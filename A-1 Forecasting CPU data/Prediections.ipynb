{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will be applying different types of forecasting techniques on the given cpu data and analyise which one of them provides better accuracy and why.\n",
    "\n",
    "We will be using folowing forecasting techniques:\n",
    "\n",
    "1) Simple Moving Average\n",
    "\n",
    "2) Weighted Moving average\n",
    "\n",
    "3) Exponential Smoothning\n",
    "\n",
    "4) Exponential Smoothning w/ trend\n",
    "\n",
    "5) Linear Regression\n",
    "\n",
    "6) Non-linear Regression\n",
    "\n",
    "7) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import time\n",
    "import pyprind\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_file = \"D:\\\\course_related_data\\\\CSEE5690\\\\VM-CPU-Stats-1-Day.csv\"\n",
    "store_file = file('D:\\\\course_related_data\\\\CSEE5690\\\\cpu_analytics_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_data = pd.read_csv(src_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narsi\\Anaconda2\\lib\\site-packages\\numpy\\lib\\function_base.py:3823: RuntimeWarning:\n",
      "\n",
      "Invalid value encountered in percentile\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>IntervalSecs</th>\n",
       "      <th>Instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146004.000000</td>\n",
       "      <td>146004.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>298.213316</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>628.430860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12986.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Value  IntervalSecs  Instance\n",
       "count  146004.000000      146004.0       0.0\n",
       "mean      298.213316         300.0       NaN\n",
       "std       628.430860           0.0       NaN\n",
       "min         3.000000         300.0       NaN\n",
       "25%        48.000000         300.0       NaN\n",
       "50%       106.000000         300.0       NaN\n",
       "75%       296.000000         300.0       NaN\n",
       "max     12986.000000         300.0       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146004 entries, 0 to 146003\n",
      "Data columns (total 9 columns):\n",
      "Value           146004 non-null int64\n",
      "Timestamp       146004 non-null object\n",
      "MetricId        146004 non-null object\n",
      "Unit            146004 non-null object\n",
      "Description     146004 non-null object\n",
      "Entity          146004 non-null object\n",
      "EntityId        146004 non-null object\n",
      "IntervalSecs    146004 non-null int64\n",
      "Instance        0 non-null float64\n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cpu_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_freq = cpu_data['Value']\n",
    "E_id_list = cpu_data.Entity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_9 = np.array([1,2,3,4,5,4,3,2,1],dtype = np.float32)\n",
    "weight_9 = weight_9/np.sum(weight_9)\n",
    "weight_11 = np.array([1,2,3,4,5,6,5,4,3,2,1],dtype = np.float32)\n",
    "weight_11 = weight_11/np.sum(weight_11)\n",
    "weight_7 = np.array([1,2,3,4,3,2,1],dtype = np.float32)\n",
    "weight_7 = weight_7/np.sum(weight_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~narsi/75.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1 = go.Scatter( y=weight_9, marker={'color': 'red', 'symbol': 104, 'size': \"10\"}, \n",
    "                    mode=\"markers+lines\", name='Weight 9 array')\n",
    "\n",
    "trace2 = go.Scatter( y=weight_11, marker={'color': 'green', 'symbol': 104, 'size': \"10\"}, \n",
    "                    mode=\"markers+lines\", name='Weight 11 array')\n",
    "\n",
    "trace3 = go.Scatter( y=weight_7, marker={'color': 'blue', 'symbol': 104, 'size': \"10\"}, \n",
    "                    mode=\"markers+lines\", name='Weight 7 array')\n",
    "\n",
    "data=go.Data([trace1, trace2, trace3])\n",
    "layout=go.Layout(title=\"Three Different weight distribution for Weighted averaging\")\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:48\n"
     ]
    }
   ],
   "source": [
    "mo_avg_7 = []\n",
    "mo_avg_9 = []\n",
    "mo_avg_11 = []\n",
    "bar = pyprind.ProgBar(len(E_id_list), stream=1)\n",
    "for E_id in E_id_list:\n",
    "    id_list = cpu_data[cpu_data['Entity'] == E_id].index.tolist()\n",
    "    for window in [7,9,11]:\n",
    "        x = np.empty(len(id_list)-window)\n",
    "        counter = 0\n",
    "        for i in id_list[window:]:\n",
    "            x[counter] = np.mean(cpu_freq[i-window:i])\n",
    "            counter += 1\n",
    "        if window == 7:\n",
    "            mo_avg_7.append(x)\n",
    "        elif window == 9:\n",
    "            mo_avg_9.append(x)\n",
    "        elif window == 11:\n",
    "            mo_avg_11.append(x)\n",
    "    bar.update()\n",
    "\n",
    "cPickle.dump((mo_avg_7, mo_avg_9, mo_avg_11), store_file, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:22\n"
     ]
    }
   ],
   "source": [
    "wei_mo_avg_7 = []\n",
    "wei_mo_avg_9 = []\n",
    "wei_mo_avg_11 = []\n",
    "bar = pyprind.ProgBar(len(E_id_list), stream=1)\n",
    "for E_id in E_id_list:\n",
    "    id_list = cpu_data[cpu_data['Entity'] == E_id].index.tolist()\n",
    "    for window in [7,9,11]:\n",
    "        x = np.empty(len(id_list)-window)\n",
    "        counter = 0\n",
    "        if window == 7:\n",
    "            weight_ = weight_7\n",
    "        elif window == 9:\n",
    "            weight_ = weight_9\n",
    "        elif window == 11:\n",
    "            weight_ = weight_11\n",
    "        \n",
    "        for i in id_list[window:]:\n",
    "            x[counter] = np.sum(cpu_freq[i-window:i] * weight_)\n",
    "            counter += 1\n",
    "        if window == 7:\n",
    "            wei_mo_avg_7.append(x)\n",
    "        elif window == 9:\n",
    "            wei_mo_avg_9.append(x)\n",
    "        elif window == 11:\n",
    "            wei_mo_avg_11.append(x)\n",
    "    bar.update()\n",
    "\n",
    "cPickle.dump((wei_mo_avg_7, wei_mo_avg_9, wei_mo_avg_11), store_file, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:46\n"
     ]
    }
   ],
   "source": [
    "ES_pred = []\n",
    "bar = pyprind.ProgBar(9*len(E_id_list), stream=1)\n",
    "for a in range(1,10):\n",
    "    E_id_array = []\n",
    "    for E_id in E_id_list:\n",
    "        id_list = cpu_data[cpu_data['Entity'] == E_id].index.tolist()\n",
    "        x = np.empty(len(id_list))\n",
    "        x[0] = cpu_freq[id_list[0]]\n",
    "        counter = 1\n",
    "        for i in id_list[1:]:\n",
    "            x[counter] = x[counter-1] + (a/10.0) * (cpu_freq[i-1] - x[counter-1])\n",
    "            counter += 1\n",
    "        E_id_array.append(x)\n",
    "        bar.update()\n",
    "    \n",
    "    ES_pred.append(E_id_array)\n",
    "\n",
    "cPickle.dump(ES_pred, store_file, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Exponential Smoothing with trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:49\n"
     ]
    }
   ],
   "source": [
    "EST_pred = []\n",
    "bar = pyprind.ProgBar(9*9*len(E_id_list), stream=1)\n",
    "for a in range(1,10):\n",
    "    for d in range(1,10):\n",
    "        E_id_array = []\n",
    "        for E_id in E_id_list:\n",
    "            id_list = cpu_data[cpu_data['Entity'] == E_id].index.tolist()\n",
    "            x = np.empty(len(id_list))\n",
    "            x[0] = cpu_freq[id_list[0]]\n",
    "            T = 0.0\n",
    "            F = x[0]\n",
    "            counter = 1\n",
    "            for i in id_list[1:]:\n",
    "                F = x[counter - 1] + a/10.0 * (cpu_freq[i-1] - x[counter-1])\n",
    "                T = T + d/10.0 * (F - x[counter-1])\n",
    "                x[counter] = F + T\n",
    "                counter += 1\n",
    "            E_id_array.append(x)\n",
    "            bar.update()\n",
    "        EST_pred.append(E_id_array)\n",
    "\n",
    "cPickle.dump(EST_pred, store_file, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = file('D:\\\\course_related_data\\\\CSEE5690\\\\cpu_analytics_20160831-143731.pkl', 'rb')\n",
    "value1 = cPickle.load(f)\n",
    "value2 = cPickle.load(f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
