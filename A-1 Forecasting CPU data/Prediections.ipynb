{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will be applying different types of forecasting techniques on the given cpu data and analyise which one of them provides better accuracy and why.\n",
    "\n",
    "We will be using folowing forecasting techniques:\n",
    "\n",
    "1) Simple Moving Average\n",
    "\n",
    "2) Weighted Moving average\n",
    "\n",
    "3) Exponential Smoothning\n",
    "\n",
    "4) Exponential Smoothning w/ trend\n",
    "\n",
    "5) Moving weighted average EST\n",
    "\n",
    "6) Linear Regression\n",
    "\n",
    "7) Non-linear Regression (2nd order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import time\n",
    "import pyprind\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linux src files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_file = \"/home/narsi/Documents/CSEE5690_data/VM-CPU-Stats-1-Day.csv\"\n",
    "#store_file = file('/home/narsi/Documents/CSEE5690_data/cpu_analysis/cpu_analytics_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.pkl', 'wb')\n",
    "store_folder = \"/home/narsi/Documents/CSEE5690_data/cpu_analysis/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows src files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_file = \"D:\\\\course_related_data\\\\CSEE5690\\\\VM-CPU-Stats-1-Day.csv\"\n",
    "store_folder = \"D:\\\\course_related_data\\\\CSEE5690\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_data = pd.read_csv(src_file).iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_freq = np.array(cpu_data['Value'],dtype = np.float32)\n",
    "E_id_list = cpu_data.Entity.unique()\n",
    "E_select = [25,60,110,225,350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [3, 5, 9, 11, 20]\n",
    "trace_1 = go.Scatter(y=cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[25]].index.tolist(), dtype=np.int32))-1], marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name=E_id_list[25]+' Mean'+\n",
    "                     str(np.mean(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[25]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    +' Varience'+ str(np.var(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[25]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    )\n",
    "trace_2 = go.Scatter(y=cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[60]].index.tolist(), dtype=np.int32))-1], marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name=E_id_list[60]+' Mean'+\n",
    "                     str(np.mean(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[60]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    +' Varience'+ str(np.var(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[60]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    )\n",
    "trace_3 = go.Scatter(y=cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[110]].index.tolist(), dtype=np.int32))-1], marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name=E_id_list[110]+' Mean'+\n",
    "                     str(np.mean(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[110]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    +' Varience'+ str(np.var(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[110]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    )\n",
    "trace_4 = go.Scatter(y=cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[225]].index.tolist(), dtype=np.int32))-1], marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name=E_id_list[225]+' Mean'+\n",
    "                     str(np.mean(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[225]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    +' Varience'+ str(np.var(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[225]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    )\n",
    "trace_5 = go.Scatter(y=cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[350]].index.tolist(), dtype=np.int32))-1], marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name=E_id_list[350]+' Mean'+\n",
    "                     str(np.mean(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[350]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    +' Varience'+ str(np.var(cpu_freq[(len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id_list[350]].index.tolist(), dtype=np.int32))-1]))\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~narsi/285.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=go.Data([trace_1,trace_2,trace_3,trace_4,trace_5])\n",
    "layout=go.Layout()\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146004 entries, 146003 to 0\n",
      "Data columns (total 9 columns):\n",
      "Value           146004 non-null int64\n",
      "Timestamp       146004 non-null object\n",
      "MetricId        146004 non-null object\n",
      "Unit            146004 non-null object\n",
      "Description     146004 non-null object\n",
      "Entity          146004 non-null object\n",
      "EntityId        146004 non-null object\n",
      "IntervalSecs    146004 non-null int64\n",
      "Instance        0 non-null float64\n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cpu_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                     100%\n",
      "[#########################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "MA = pd.DataFrame(columns=['Subject','Window','TS_Score','MAD','A','F'])\n",
    "bar = pyprind.ProgBar(len(E_select)*5, stream=1)\n",
    "dataframe_counter = 0\n",
    "for E_id in E_id_list[E_select]:\n",
    "    id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype=np.int32))-1\n",
    "    for window in [3, 5, 9, 11, 20]:\n",
    "        x = np.empty(len(id_list) - window)\n",
    "        counter = 0\n",
    "        for i in id_list[window:]:\n",
    "            X = cpu_freq[i - window:i]\n",
    "            x[counter] = np.sum(X) * 1.0 / window\n",
    "            counter += 1\n",
    "\n",
    "        TS = np.sum(cpu_freq[id_list[window:]]-x)/(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x))\n",
    "        #MA.append({'Window': window, 'Actual_Data': cpu_freq[id_list[window:]], 'Predicted': x, 'TS_Score': TS}, ignore_index=True)\n",
    "        MA.loc[dataframe_counter] = [E_id,window,TS,(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x)),cpu_freq[id_list[window:]],x]\n",
    "        dataframe_counter += 1\n",
    "        bar.update()\n",
    "\n",
    "MA.to_csv(store_folder+'/MA_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                     100%\n",
      "[#########################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "WMA = pd.DataFrame(columns=['Subject','Window','TS_Score','MAD','A','F'])\n",
    "bar = pyprind.ProgBar(len(E_select)*5, stream=1)\n",
    "dataframe_counter = 0\n",
    "for E_id in E_id_list[E_select]:\n",
    "    id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype=np.int32))-1\n",
    "    for window in [3, 5, 9, 11, 20]:\n",
    "        x = np.empty(len(id_list)-window)\n",
    "        counter = 0\n",
    "        weight_ = np.arange(window,dtype = np.float32)+1\n",
    "        weight_ = weight_/np.sum(weight_)\n",
    "        \n",
    "        for i in id_list[window:]:\n",
    "            x[counter] = np.sum(cpu_freq[i-window:i] * weight_)\n",
    "            counter += 1\n",
    "        \n",
    "        TS = np.sum(cpu_freq[id_list[window:]]-x)/(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x))\n",
    "        WMA.loc[dataframe_counter] = [E_id,window,TS,(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x)),cpu_freq[id_list[window:]],x]\n",
    "        dataframe_counter += 1\n",
    "        bar.update()\n",
    "WMA.to_csv(store_folder+'/WMA_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                100%\n",
      "[####################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "ES = pd.DataFrame(columns=['Subject','Alpha','TS_Score','MAD','A','F'])\n",
    "\n",
    "alpha = [0.2,0.4,0.6,0.8]\n",
    "dataframe_counter = 0\n",
    "bar = pyprind.ProgBar(len(alpha)*len(E_select), stream=1)\n",
    "for a in alpha:\n",
    "    for E_id in E_id_list[E_select]:\n",
    "        id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype = np.int32))-1\n",
    "        x = np.empty(len(id_list))\n",
    "        x[0] = cpu_freq[id_list[0]]\n",
    "        counter = 1\n",
    "        for i in id_list[1:]:\n",
    "            x[counter] = x[counter-1] + (a) * (cpu_freq[i-1] - x[counter-1])\n",
    "            counter += 1\n",
    "        \n",
    "        TS = np.sum(cpu_freq[id_list]-x)/(np.sum(np.absolute(cpu_freq[id_list]-x))/len(x))\n",
    "        ES.loc[dataframe_counter] = [E_id,a,TS,(np.sum(np.absolute(cpu_freq[id_list]-x))/len(x)),cpu_freq[id_list],x]\n",
    "        dataframe_counter +=1\n",
    "        bar.update()\n",
    "ES.to_csv(store_folder+'/ES_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Exponential Smoothing with trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                100%\n",
      "[####################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "EST = pd.DataFrame(columns=['Subject','Alpha','TS_Score','MAD','A','F'])\n",
    "d = 0.5\n",
    "alpha = [0.2,0.4,0.6,0.8]\n",
    "dataframe_counter = 0\n",
    "bar = pyprind.ProgBar(len(alpha)*len(E_select), stream=1)\n",
    "for a in alpha:\n",
    "    for E_id in E_id_list[E_select]:\n",
    "        id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype = np.int32))-1\n",
    "        x = np.empty(len(id_list))\n",
    "        x[0] = cpu_freq[id_list[0]]\n",
    "        T = 0.0\n",
    "        F = x[0]\n",
    "        counter = 1\n",
    "        for i in id_list[1:]:\n",
    "            F = x[counter - 1] + a * (cpu_freq[i-1] - x[counter-1])\n",
    "            T = T + d * (F - x[counter-1])\n",
    "            x[counter] = F + T\n",
    "            counter += 1\n",
    "\n",
    "        TS = np.sum(cpu_freq[id_list]-x)/(np.sum(np.absolute(cpu_freq[id_list]-x))/len(x))\n",
    "        EST.loc[dataframe_counter] = [E_id,a,TS,(np.sum(np.absolute(cpu_freq[id_list]-x))/len(x)),cpu_freq[id_list[window:]],x]\n",
    "        dataframe_counter += 1\n",
    "        bar.update()\n",
    "EST.to_csv(store_folder+'/EST_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Windowed Exponential Smoothing with trend V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "WEST = pd.DataFrame(columns=['Subject','Alpha','Window','TS_Score','A','F'])\n",
    "d = 0.5\n",
    "alpha = [0.2,0.4,0.6,0.8]\n",
    "bar = pyprind.ProgBar(5*4*len(E_select), stream=1)\n",
    "dataframe_counter = 0\n",
    "for a in alpha:\n",
    "    for E_id in E_id_list[E_select]:\n",
    "        id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype = np.int32))-1\n",
    "        for window in [3, 5, 9, 11, 20]:\n",
    "            x = np.empty(len(id_list))\n",
    "            weight_ = np.arange(window,dtype = np.float32)+1\n",
    "            weight_ = weight_/np.sum(weight_)\n",
    "            x[0:window] = cpu_freq[id_list[0:window]]\n",
    "            T = 0.0\n",
    "            F = x[window-1]\n",
    "            counter = window\n",
    "            for i in id_list[window:]:\n",
    "                F = x[counter - 1] + a * (np.sum((cpu_freq[i-window:i] - x[counter-window:counter])*weight_))\n",
    "                T = T + d * (F - x[counter-1])\n",
    "                x[counter] = F + T\n",
    "                if x[counter] <= 0:\n",
    "                    x[counter] = np.sum(cpu_freq[i-window:i]*weight_)\n",
    "                counter += 1\n",
    "\n",
    "            TS = np.sum(cpu_freq[id_list[window:]]-x[window:])/(np.sum(np.absolute(cpu_freq[id_list[window:]]-x[window:]))/len(x))\n",
    "            WEST.loc[dataframe_counter] = [E_id,a,window,TS,cpu_freq[id_list[window:]],x[window:]]\n",
    "            dataframe_counter += 1\n",
    "            bar.update()\n",
    "WEST.to_csv(store_folder+'/WEST_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Moving Window Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                     100%\n",
      "[#########################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "PL = pd.DataFrame(columns=['Subject','Window','TS_Score','MAD','A','F'])\n",
    "bar = pyprind.ProgBar(5*len(E_select), stream=1)\n",
    "dataframe_counter = 0\n",
    "for E_id in E_id_list[E_select]:\n",
    "    id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype=np.int32))-1\n",
    "    for window in [3, 5, 9, 11, 20]:\n",
    "        x = np.empty(len(id_list)-window)\n",
    "        t = np.arange(window)\n",
    "        weight_ = np.arange(window,dtype = np.float32)+1\n",
    "        weight_ = weight_/np.sum(weight_)\n",
    "        counter = 0\n",
    "        for i in id_list[window:]:\n",
    "            (ar,br) = scipy.polyfit(t,cpu_freq[i-window:i],1)\n",
    "            x[counter] = scipy.polyval([ar,br],window)\n",
    "            counter += 1\n",
    "            \n",
    "        TS = np.sum(cpu_freq[id_list[window:]]-x)/(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x))\n",
    "        PL.loc[dataframe_counter] = [E_id,window,TS,(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x)),cpu_freq[id_list[window:]],x]\n",
    "        dataframe_counter += 1\n",
    "        bar.update()\n",
    "PL.to_csv(store_folder+'/PL_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Moving Window 2nd order Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%                     100%\n",
      "[#########################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "PL2 = pd.DataFrame(columns=['Subject','Window','TS_Score','MAD','A','F'])\n",
    "bar = pyprind.ProgBar(5*len(E_select), stream=1)\n",
    "dataframe_counter = 0\n",
    "for E_id in E_id_list[E_select]:\n",
    "    id_list = (len(cpu_data) - np.array(cpu_data[cpu_data['Entity'] == E_id].index.tolist(), dtype=np.int32))-1\n",
    "    for window in [3, 5, 9, 11, 20]:\n",
    "        x = np.empty(len(id_list)-window)\n",
    "        t = np.arange(window)\n",
    "        weight_ = np.arange(window,dtype = np.float32)+1\n",
    "        weight_ = weight_/np.sum(weight_)\n",
    "        counter = 0\n",
    "        for i in id_list[window:]:\n",
    "            z = np.polyfit(t,cpu_freq[i-window:i],2)\n",
    "            p = np.poly1d(z)\n",
    "            x[counter] = p(window)\n",
    "            counter += 1\n",
    "            \n",
    "        TS = np.sum(cpu_freq[id_list[window:]]-x)/(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x))\n",
    "        PL2.loc[dataframe_counter] = [E_id,window,TS,(np.sum(np.absolute(cpu_freq[id_list[window:]]-x))/len(x)),cpu_freq[id_list[window:]],x]\n",
    "        dataframe_counter += 1\n",
    "        bar.update()\n",
    "PL2.to_csv(store_folder+'/PL2_'+time.strftime(\"%Y%m%d-%H%M%S\")+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting different methods results for \"kc-pd-sql01\" VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[original_signal] = PL[(PL['Subject'] == 'kc-pd-sql01') & (PL['Window'] ==  20)].A.tolist()\n",
    "x_axis = np.arange(1,len(original_signal)+1)\n",
    "[MA_20W_signal] = MA[(MA['Subject'] == 'kc-pd-sql01') & (MA['Window'] ==  20)].F.tolist()\n",
    "[WMA_20W_signal] = WMA[(WMA['Subject'] == 'kc-pd-sql01') & (WMA['Window'] ==  20)].F.tolist()\n",
    "[ES_A8_signal] = ES[(ES['Subject'] == 'kc-pd-sql01') & (ES['Alpha'] ==  0.8)].F.tolist()\n",
    "ES_A8_signal = ES_A8_signal[20:]\n",
    "[EST_A8_signal] = EST[(EST['Subject'] == 'kc-pd-sql01') & (EST['Alpha'] ==  0.8)].F.tolist()\n",
    "EST_A8_signal = EST_A8_signal[20:]\n",
    "[WEST_3W_A8_signal] = WEST[(WEST['Subject'] == 'kc-pd-sql01') & (WEST['Alpha'] ==  0.8) & (WEST['Window'] ==  20)].F.tolist()\n",
    "[PL_20W_signal] = PL[(PL['Subject'] == 'kc-pd-sql01') & (PL['Window'] ==  20)].F.tolist()\n",
    "[PL2_20W_signal] = PL2[(PL2['Subject'] == 'kc-pd-sql01') & (PL2['Window'] ==  20)].F.tolist()\n",
    "#trace_orignal = go.Scatter(x = range(1,len()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [3, 5, 9, 11, 20]\n",
    "trace_o = go.Scatter( x = x_axis,y=original_signal, marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name='Original Signal')\n",
    "trace_est = go.Scatter( x = x_axis,y=EST_A8_signal, marker={'size': \"5\"}, \n",
    "                    mode=\"markers\", name='Exponential Smoothening w/ Trend')\n",
    "trace_pl = go.Scatter( x = x_axis,y=PL_20W_signal, marker={'size': \"5\"}, \n",
    "                    mode=\"lines\", name='Moving Window 2nd order Regression Linear', line={'dash':'dash'})\n",
    "trace_pl2 = go.Scatter( x = x_axis,y=PL2_20W_signal, marker={'size': \"5\"}, line={'dash':'dot'}, \n",
    "                    mode=\"markers+lines\", name='Moving Window 2nd order Regression 2nd order polynomial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~narsi/289.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=go.Data([trace_o,trace_est,trace_pl,trace_pl2])\n",
    "layout=go.Layout()\n",
    "figure=go.Figure(data=data,layout=layout)\n",
    "py.iplot(figure)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
