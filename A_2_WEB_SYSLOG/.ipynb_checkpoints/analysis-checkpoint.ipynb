{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_folder = '/home/narsi/Documents/CSEE5690_data/A2_WEB_SYS_LOG/curated_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)  # Add it to the list.\n",
    "\n",
    "    return file_paths  # Self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = get_filepaths(src_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_log = pd.DataFrame({'url' : [],'count' : [],'date' : []})\n",
    "unique_days = []\n",
    "for F in file_path:\n",
    "    log_data = pd.read_csv(F,',',header=None, error_bad_lines=False)\n",
    "    x = pd.Series.value_counts(log_data[4])\n",
    "    urls = []\n",
    "    count = np.asarray(x)\n",
    "    date = []\n",
    "    \n",
    "    unique_days.append(log_data[1][0])\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        date.append(log_data[1][0])\n",
    "        urls.append(x.axes[0][i])\n",
    "    dummy = pd.DataFrame({'url' : urls,'count' : count,'date' : date})\n",
    "    final_log = final_log.append(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_urls = np.asarray(pd.Series.value_counts(final_log['url']).axes[0])\n",
    "unique_date = pd.DataFrame({'date':pd.to_datetime(unique_days)}).sort_values(by='date')\n",
    "final_log['date'] = pd.to_datetime(final_log['date'])\n",
    "url_by_date_count = np.zeros((len(unique_urls),len(unique_date)))\n",
    "for i in range(len(unique_urls)):\n",
    "    for j in range(len(unique_date)):\n",
    "        x = np.asarray(final_log['count'][(final_log['date'] == unique_date['date'][j]) & (final_log['url'] == unique_urls[i])])\n",
    "        if len(x) == 0:\n",
    "            url_by_date_count[i][j] = 0\n",
    "        else:\n",
    "            url_by_date_count[i][j] = x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
